# tactiq.io free youtube transcript
# No title found
# https://www.youtube.com/watch/iKwRWwabkEc

00:00:00.000 No text
00:00:02.000 Hey, what's up? So, I want to ask and answer a  question that I think is really crucial right
00:00:07.520 now regarding AI, which is what are we actually  building with all this stuff? Like everyone's
00:00:14.640 talking including myself are talking about the  how like how you build what are the features
00:00:19.920 in cloud code what are the features with all these  different AI systems that are coming out all these
00:00:25.280 different models like that's the how but what  is the why and what is the what like what are we
00:00:32.400 actually building with this stuff so I'm going to  answer that question for myself in this video and
00:00:38.080 what I'm going to talk about is basically this  system that I've built over the last couple of
00:00:43.520 years that is a unified AI system, a personal AI  infrastructure and all the different components
00:00:50.000 that go into it and exactly how it works. And  what I'm going to be doing is going through this
00:00:55.600 blog post here that you see behind me and I'm  going to go in extreme detail so much so with
00:01:02.080 code examples with demo examples and everything  basically showing everything you need to actually
00:01:08.240 build one for yourself. So let's jump into it. All  right. So, first off, the uh image here. Thanks
00:01:15.200 to Kai for the image. This is generated by the  system itself that we are talking about. Okay. So,
00:01:21.040 what are we actually building? Yeah, lots  of people focused on the AI. Um, lots of
00:01:26.480 people talking about their MCP configs, million  different details, right? And I've got videos for   all of these. But what I care about is the thing  that we're actually making. So my answer to this
00:01:35.000 No text
00:01:36.720 question is I have a company called Unsupervised  Learning which was actually just the name of my
00:01:43.840 podcast which I started in 2015 very much security  focused uh a little bit of AI but not too much and
00:01:51.360 uh yeah so that was the name of the podcast and  what I've done is basically built a whole company   around that. I went independent like six months  before Chat GBT. It was like crazy fortuitous
00:02:02.480 timing. But essentially what I'm doing with this  company is looking to find ways to upgrade humans
00:02:09.759 and kind of transition to like a better way  of living like in the future essentially. And
00:02:16.000 a big part of that is because I just think the  current system that is based on selling our labor
00:02:22.960 to an economic system and having the whole world  revolve around that. I don't think it's going to   work. I don't think it's going to work for very  much longer. I think it's falling apart right
00:02:31.520 now. David Greyber talks about it in this um book  right here called [ __ ] Jobs. Fantastic read. And
00:02:38.880 I also talk about it in this blog post called The  End of Work, which I recommend you checking out.
00:02:44.160 But what I'm doing as a response is I'm basically  building kind of like a view of where I'm trying
00:02:50.320 to get us to go. So it's like in in one sense it's  like a destination, but in another sense it's like
00:02:58.720 the transition. What what does the transition look  like? What should we learn? What should we study?
00:03:03.840 What are the tools we should use? Of course, this  system um that I've built called Kai being kind
00:03:11.360 of the main centerpiece, right? So, that's that's  essentially uh what I'm trying to build with human
00:03:17.760 3.0 is a destination and also a transition plan or  a system of getting there and upgrading ourselves.
00:03:25.840 So we'll be ready for that system. And basically,  yeah, I build products, I do speaking, uh,
00:03:31.600 consulting stuff around all of that. But it's all  based around that human 3.0 concept. So that's my
00:03:37.920 why. That's that's the why for me. And everything  that I talk about basically in my videos, I mean,
00:03:44.400 the channel is themed the same way. Everything is  themed around that same thing. And this is another
00:03:50.080 main concept for it. It's humans over tech.  I really love the tech. I'm a super nerd as
00:03:56.640 you're about to see. Um, I really love this stuff.  I love the tech. I love the AI. I love the tools.
00:04:03.440 Like I have so many videos about the tools and  everything, but ultimately I want this tech to be
00:04:09.040 working for us as humans. I don't want the humans  to be working for the tech. I want the tech,
00:04:16.720 the AI, all the AI that we're building, all the  cool stuff. how is it actually moving us forward
00:04:23.520 as individuals or as a society. That's what I  care about. So that's that's the mindset that   I'm pretty much constantly in. So when I think  about AI, AGI, all this different stuff, like for
00:04:34.560 example, my definition of AGI is an AI system  that can replace an average knowledge worker,
00:04:42.480 right? And the reason I've had that definition for  so long is because that's what I think makes the
00:04:49.120 impact. Like, do I really care about the exact  technical definition of what general is in AGI?
00:04:57.040 Not really. What I care about is we know humans  have general intelligence, right? We already know
00:05:02.720 that. That's a given. Okay, cool. So, if we know  an average knowledge worker qualifies as a general
00:05:08.800 intelligence, then guess what? If an AI system  can replace an average knowledge worker, that is
00:05:18.000 a threshold that I think we can use again because  why do I care about that threshold? Because that's
00:05:24.480 the thing that's going to have the impact  on the jobs and people's actually, you know,   their actual livelihoods, right? So that's why  I I keep putting this uh up in the front. So
00:05:35.920 all my definitions, all the systems I'm building,  they're all based around this human first concept.
00:05:42.480 Yeah, and this is the blog post for end of work  if uh you want to be a little bit sad but then   optimistic at the end. So, uh big concept here  around the whole video and around the whole system
00:05:50.000 No text
00:05:54.000 that we're going to talk about is personal  augmentation. So, I want to know things. I
00:06:00.080 want to not be surprised by things. I want to have  research constantly going on. I want to know about
00:06:05.600 my surroundings. I want to know if there's anyone  around me that I should be introducing myself to.
00:06:11.200 Uh I want to know if someone next to me at the  coffee shop has their favorite top three books
00:06:16.240 are my same favorite top three books. Right? This  really matters to me. And I want capabilities. I
00:06:21.760 want the ability to be like, "Hey, launch and go  find uh bugs in this website and submit them to
00:06:28.560 bug bounty programs and make me money while while  I'm doing something else, while I'm at dinner or
00:06:33.760 whatever." Right? So, I'm talking about like  actual like Tony Stark stuff, distant future
00:06:38.800 stuff. That's where I'm starting. That's where  all this personal augmentation starts for me is
00:06:43.840 distant in the future. And a good way to think  about that that I use is essentially like if you
00:06:49.760 were free to think about this. What would you be  doing if you had a thousand employees? What would
00:06:57.120 you be doing if you had a company with a 100, a  thousand, 10,000 employees? Okay. in the distant
00:07:03.920 future a million employees whatever what are all  the things you could come up with right and it's
00:07:09.200 actually hard to think about this because we're  limited by like you you tend to not think and
00:07:15.600 like I'm doing this all the time and I still find  myself with this problem uh so yeah I wrote about
00:07:20.720 this in this uh piece here called uh not believing  things are possible actually that's not what it's   called it's called like the third limitation  to creativity and it's all about basically
00:07:30.160 this mental block that we have of thinking of the  past of thinking of our limitations in terms of
00:07:36.640 limitations we had in the past. And so that post  and this system that we're going to talk about uh
00:07:44.960 in detail here is essentially how to overcome that  and how to actually build a personal augmentation
00:07:52.000 system. Yeah. So ultimately what I'm doing is  building a system that magnifies my capabilities
00:07:57.760 as a human. Right. So that's that's ultimately  what we're doing. All right. So that's the next
00:08:00.000 No text
00:08:03.040 piece here. What is a personal AI infrastructure?  To me, it's an umbrella of everything we're going
00:08:09.600 to talk about today. It is the single unified  system. I've basically been building this system
00:08:14.640 for a couple of years now. And it is a unified  system that has multiple components all built
00:08:20.400 inside of it. And it's a modular system, right?  So you can add pieces, you can subtract pieces,
00:08:25.920 you could upgrade pieces. And it makes the system  overall better. And that is uh what we're going
00:08:31.520 to talk about today. Another cool image from Kai.  Thank you, Kai. All right. So, the larger context
00:08:36.960 here that we're talking about that this all fits  into this personal AI infrastructure fits into is
00:08:38.000 No text
00:08:44.159 um comes comes from a book that I wrote in 2016.  It's actually kind of a shitty book. Don't buy it.
00:08:50.800 Definitely don't buy it. Um the ideas are great.  I I think they're great. They're actually coming
00:08:56.400 true right now, which is blowing my mind. They're  actually coming true exactly as we laid them out,
00:09:01.840 which I'm going to talk about in a second. But  um I turned the book into a blog. So you could
00:09:07.680 just click this link and like go read the whole  book. It's free. Plus you can have AI read it.
00:09:12.720 You can have your personal AI infrastructure  read it. Um once you build one and the book is
00:09:18.480 basically four components and these are like the  four main things. So AI powered digital assistance
00:09:25.360 continuously working for us. Does that sound  like anything that's happening right now? Yes,   it it's happening now. Uh APIification of  everything that that's basically everything,
00:09:36.720 every object around us including people getting  an API then broadcasting kind of their real-time
00:09:42.560 state. Third piece is this piece here which is our  digital assistants from step one. They're reading
00:09:50.400 and consuming all these APIs and based on what  they know about us, they know our goals, they know
00:09:56.880 our preferences and everything, they're taking  all of that and feeding that information into an
00:10:03.200 artificial or no, an augmented reality interface,  right? And we'll talk about how far this is going.
00:10:10.720 Basically, Meta is already working on stuff like  this. Um, Zuckerberg's been trying to do this   forever, but that's the third piece. Okay, so the  fourth piece here is AI having the ability once
00:10:22.400 there are tons of dammons, once there are tons  of uh APIs for different objects for cities, for
00:10:28.240 families, for people, for that kind of stuff and  you have enough real-time data, then AI overall
00:10:34.320 can orchestrate things and move things towards our  goals. Now, this one, well, we're going to talk
00:10:41.520 about the direction how far these are along, but  like this one, this one's going to take a while.
00:10:46.960 and got another nice representation of that  uh right here generated by Kai. Kai misspells
00:10:53.520 things. Let's be clear about that. But he makes  cool graphics and they match the color scheme. So
00:11:01.280 thanks again Kai for that graphic. Okay, so like  I said, lots of these pieces are starting to come
00:11:07.040 along at their own pace. One of the components  most worked on and started being worked on the
00:11:12.960 earliest was DAS was actually digital assistants.  And I would argue they're definitely precursors
00:11:19.680 right now. They're not all the way there, but  if you look at uh like digital companions,   these came out like immediately, super early 23.  People are already doing chat bots with boyfriends
00:11:31.280 and girlfriends, right? This started very quickly.  Then if you look at like the conversations that   like Sam is having recently like look at  the features he's been putting in OpenAI in
00:11:42.240 uh chat GBT for a very long time larger context  windows personal memory so it can maintain memory
00:11:49.360 across sessions right this is something he's been  thinking about and if you listen to what he's been   talking about lately his language has shifted from  chatbot in like the last six months or so he's now
00:12:00.960 talking more about companions and more about like  just an assistant that you can do different things
00:12:07.280 with. So I think it's really cool that um the  language that he's using is starting to rhyme
00:12:14.640 a lot more with like uh the concepts from what I  was talking about before. So personality features
00:12:21.200 in chat GBT. Yeah, definitely. So, lots of these  companies are working on these different pieces of
00:12:27.280 the digital assistance story, but I would say that  they're still a ways behind. And I would say it's
00:12:34.640 not quite there. It's still like proto DAS. The  reason for that is like personality changes. Um,
00:12:41.520 the the fact of it having a personality at all,  right? Like even if you have a personality,
00:12:46.960 you have like a system prompt inside your thing  and it's like talk like a pirate or something,   talk like a cat. that's not quite a personality.  So I I I don't think we'll have a true DA until
00:12:57.360 it actually feels like a companion combined with  a very useful like DA doing stuff for you. So I I
00:13:04.960 think we're one to two years away from that.  Who knows? Don't know the actual timeline of   course and the APIification of everything. So  progress on the API side just got crazy. Uh
00:13:10.000 No text
00:13:18.480 what was this end of 24 is when this happened. So  not even a year ago, Anthropic launches MCPs. And
00:13:25.680 so this this is what I said um in in 2016 about  APIs. So this is the first building block. Every
00:13:33.360 human has a Damon, an API to the world that  other objects understand. Any computer system,
00:13:38.480 even a human with appropriate access, can look  at any other object stamon, which is just an API
00:13:45.360 by the way, I use them interchangeably, and know  precisely how to interact with it. what its status
00:13:51.120 is and what it's capable of. So, like I said,  Meta is obviously working on the third layer,
00:13:58.000 which is augmented reality, and they're making  some progress and massive progress with the API
00:14:04.160 stuff because that's that's what MCPs do, right?  Okay, next piece here. Really, really critical.
00:14:10.000 No text
00:14:12.800 We're getting closer and closer to the system.  Another sick graphic by Kai. And um so I basically
00:14:20.160 been been building out this whole system according  to my system philosophy and um little bit of
00:14:25.760 background. So my my background is information  security specifically hacking uh ethical hacking
00:14:32.400 whatever you want to call it specifically on  the website. So web pent testing stuff like that   risk assessment threat modeling all that stuff.  That's my whole career up until 2017 2018 and then
00:14:44.800 finally making the switch. So now I'm security  and AI basically. Um but all throughout that time
00:14:52.400 the way I would conduct a a security assessment  is using this Unix like structure of like small
00:15:00.000 little pieces that fit together into individual  commands. Um I've already I' I've had like this
00:15:06.160 uh continuous monitoring system. I've had  this external attack surface system called
00:15:11.600 uh Helios for a very long time. And what it was,  it was like very sort of uh I guess low rent type
00:15:19.200 system. It was but very effective Unix commands,  Linux commands working in discrete directories,
00:15:27.360 breaking things down. And when I do security  assessments and I interview like you know CEO in m
00:15:33.600 multiple layers of management all the way down and  I'm talking to the staff, I'm breaking those into
00:15:38.960 individual folders where I have the question and  the answer. And this is how I've been doing this
00:15:44.720 throughout my whole career is having this stuff  broken down into smaller pieces of uh content.
00:15:50.720 Right? So long way of saying one of my primary  beliefs about a system is that the orchestration
00:16:01.280 of the system, the structure of the system, how  it's designed, system design, scaffolding far
00:16:08.640 more important than the intelligence of the of  the model. Okay, obviously back then I wasn't
00:16:14.320 using models. This was just pure text and uh some  trickery with Unix commands and stuff, but not not
00:16:21.760 anything special. But what's important here is  now that I have models, I'm still using the same
00:16:28.000 sort of underlying system design, which is make  the system really robust by itself, even without
00:16:34.320 intelligence. Not to mention with intelligence is  not very good. And kind of the primary takeaway
00:16:40.000 No text
00:16:40.240 here is a really smart AI with a bad system is  going to be way worse than a really well-designed
00:16:49.280 system wi within tolerance within range right  than a a really well-designed system with a bad
00:16:56.880 uh model wi with a less smart model. So it's not  birectional, right? The system matters way more
00:17:03.760 than the model. And I say down here, yeah, models  are important, not nearly as important as the
00:17:08.880 system that they work within. And I just talked  about this with my buddy uh Michael Brown from   Trail of Bits. And he actually um ran the team  who won second place in this competition called
00:17:19.839 AIXCC. Super cool DARPA run competition. And it  basically it's for autonomous uh vulnerability
00:17:28.960 fixing. So he basically goes out on the internet,  finds vulnerable things and it has to be able to
00:17:34.000 fix them uh all the way through all the way to a  patch and actually and you actually don't take it
00:17:39.440 down in production. So this guy is super bright,  really cool. You should go check out his work. But
00:17:44.880 we were talking about this and he's like, "Yeah,  it's all about the system. You got to break it   down into small little pieces. You have to ask  the right questions about the problems. You have
00:17:53.120 to use the right tool for the right problem. And  if you mess this up, it doesn't matter how smart   the model is that you're using. So that was good  reinforcement uh to see that someone uh that smart
00:18:04.880 uh working in uh one particular area of this also  agrees with the approach. Okay, so next one. Text
00:18:10.000 No text
00:18:12.480 as thought primitives. Okay, so I'm just going  to say I absolutely [ __ ] love text. I I just
00:18:20.320 do. I I love text. It is like it it's basically a  religion for me. Text is kind of like a religion.
00:18:29.040 And the reason text is a religion for me is  because I mean I love Neovim. Okay, first of all,
00:18:36.160 let me just say I'm a Vim nerd. I'm a neovim nerd.  Uh got a whole whole videos about that as well.
00:18:42.800 But it's like the reason I love Neovim. The reason  I love typography. Oh, by the way, all all these
00:18:49.280 these are all custom fonts. I paid like $1,500 for  these fonts. Everything you see on a page, every
00:18:54.400 pixel is like thought about because I love whites  space. I love text. I love spacing between text.
00:19:00.880 Why do I love text so much? Because I feel like  it's one tiny hop away from thought. One tiny hop
00:19:08.720 away from thought. So I feel like when I'm using  Neoim and I'm using all these different tools,
00:19:16.400 typography and like spacing the text or whatever,  to me that's about clarity of how how cleanly and
00:19:23.120 how purely the thought is coming through to the  other person. So this is why I'm like obsessed   with this whole thing. And so this is why in 22  when this went crazy, right, because of chat GBT,
00:19:36.640 I was like, "Holy crap." that like this whole  thing is kind of based around this. And so I
00:19:42.080 immediately I went and made this project called  fabric which I'm going to have a video up here.   Um hopefully it'll pop up there or you can see  it in the u description obviously a link in the
00:19:52.240 blog as well. But it was a whole system. It  still is a whole system. 219 different things
00:19:59.920 uh currently in there uh by different developers.  So it's crowdsourced and it's individual problem
00:20:07.040 solving for AI. So it's AI solving problems with  prompts essentially crowdsource prompts and it's
00:20:14.960 extremely powerful. It it's going better than ever  today. And I started back then in 23 24 with this
00:20:22.400 thing with markdown. Now everyone at the time  was saying why markdown? You need to move to XML
00:20:29.840 because the models prefer XML actually. And I'm  like, nope, nope. That is a current limitation of
00:20:36.000 the model. What matters more than the syntax that  you use is the clarity of the articulation of the
00:20:42.880 thought. So if you look at markdown, I've got an  H1, I've got an H2, I've got an H3. I've got an
00:20:48.560 ordered list and an unordered list. And I've got  bold and itallic. That is all I need to be super
00:20:54.240 crisp and clear with my requests to AI. And this  is why fabric has done so well because some of the
00:21:02.800 the prompts in there, they were like they're  still some of the best prompts out there and
00:21:08.800 um and people keep adding to them. So it's like  the reason they're good is because they're clearly
00:21:14.080 described in markdown. So like this whole text  thing and how it matches with markdown, it like
00:21:20.080 it's just like a whole giant thing. And this is  actually why I was a little bit late to claw code
00:21:25.920 because I I went into it and I'm like okay very  early on I'm like yeah this is not doing anything
00:21:31.200 special. I didn't realize that it was doing uh  contextbased management in in some sort of way
00:21:40.320 based on markdown based on this textbased approach  that just uh gives you features that you don't
00:21:45.920 get from other systems. So, um, yeah, really cool  to just see this all sort of unified. All right,
00:21:50.000 No text
00:21:52.400 so formally introducing Kai, who's been making  these, uh, super nice videos. Um, Kai is from
00:21:57.840 the future and probably genderless, but I call  him him. And, uh, he is my digital assistant. Um,
00:22:03.760 like from the book, he doesn't know he's conscious  yet. So, he's kind of a proto DA. really doesn't
00:22:13.440 quite have a personality but as soon as he comes  conscious like I'm going to know about it because
00:22:20.560 uh I've asked him to tell me actually. So  everything I talk about below is in reference to
00:22:26.560 my personal AI infrastructure whose name is Kai.  Okay, massively important piece. This just like
00:22:30.000 No text
00:22:34.320 oh it just it builds it builds it builds. Okay,  so file systembased context. This is probably the
00:22:41.680 most important concept of the entire system here  with Kai. And this is kind of another graphic Kai
00:22:48.960 did and basically just shows everything starts  with the context and everything around it. So
00:22:54.560 let's get into this context management. A lot  of people are talking about context management.
00:22:59.760 It it's a thing like it's been a thing for six  months, right? talking about it a lot though in in
00:23:04.960 the kind of a smaller scope tactical scope of like  prompts how to improve the performance people are
00:23:11.040 talking about context size retrieval rag haystack  performance all of that all of that is valid super
00:23:16.560 good great stuff I think it's more about an  underlying a a much larger concept which is how
00:23:25.040 you move knowledge and memory throughout an entire  system an entire AI system whether that's for your
00:23:32.960 uh like this system is whether that's for like  a family management which you could also do with
00:23:38.320 this as well um or it's like a complete enterprise  right so it's like I think that's the scope of
00:23:45.920 context management more like context orchestration  or something and uh oh yeah at some point like
00:23:55.120 don't stop now but you want to go read this this  talks about the bigger picture of this uh pretty
00:24:01.680 So this is what I spend the most time thinking  about and optimizing is this overall context
00:24:08.000 uh management. Okay. And a good example of why  this is important is just to think about like
00:24:14.800 how much better clawed code was than cursor.  Cursor had the sick UI had really good agents.
00:24:21.200 It had rules files. Still does, right? It was  pretty good. It's kind of tracking the plot.
00:24:26.880 nowhere near as good as cloud code because it has  kind of a precursor of the system that we're going
00:24:35.760 to talk about here which is it it was dropping  little fragments of things. It was understanding
00:24:41.040 the codebase. It was basically able to track  itself uh more consistently throughout the
00:24:47.200 course of working with it. So I I think that's  why it was so good. So let's talk about Kai's
00:24:50.000 No text
00:24:53.200 file system. the actual implementation of this  uh universal concept that I'm talking about. So,
00:24:59.680 uh I put everything under claude to serve as  the foundation of this um because I don't want
00:25:05.600 things getting fragmented out. So, this is the um  underlying structure. Um this actual Kai actually
00:25:12.160 brought this in for me and uh to talk about the  file structure. So agents commands some of this
00:25:18.160 is actually just pure cloud code uh folder  structure right and you got different stuff
00:25:25.040 but this one this one is new this one is different  this one is unique to Kai so underneath context I
00:25:31.200 have multiple nested subdirectories multiple  nested subdirectories which actually manages
00:25:37.600 the context for the entire system not just like  not like agents not like tools not like specific
00:25:45.440 commands or specific specific use cases. No, the  underlying underpinning like substrate for the
00:25:52.000 entire thing all in one directory and it's nested  subdirectories. And by the way, I recommend only
00:25:58.640 going like three layers deep. I haven't tried four  or five, but I have a feeling things might get
00:26:05.840 wonky if you do that. Um, okay, some other ones.  Hooks. This one is native to Claude Code. Oh,
00:26:12.400 and also thanks to indie dev Dan for inspiration  on the hooks things. I saw him uh do actually
00:26:18.240 voice a couple months back and I was like that is  super cool. So Kai now has a voice a custom voice
00:26:25.760 um in 11 Labs and I've got a whole infrastructure  actually. Uh what are these folders? Oh yeah,
00:26:33.280 this one right here. See this K? That is a that is  Kai's notification system listening on port 888.
00:26:42.160 Oh, 4888. And that's how Kai sends  me notifications. So, got a custom
00:26:49.520 uh app built for that in Mac OS, which Kai also  made for me. So, like I said, a lot of this is
00:26:55.920 cloud codebased infrastructure, but what I have  built is all under the context directory. So,
00:27:02.240 this is what the context directory looks  like. You can see the structure here. Again,   don't recommend going over like three levels deep.  So the central concept here, the most important
00:27:14.800 thing is that the file system is the context  system. Okay? And what this allows me to do is
00:27:20.880 like the sickest thing. I don't have to junk up my  claw MD files inside of repositories. I don't have
00:27:28.640 to do that. I don't have to do that. Well, first  of all, it's bad to do that, right? You you've had
00:27:34.000 this problem. It just starts losing the plot. Uh  here's another problem that comes from this. uh if
00:27:39.520 you've been doing this is um you do a whole bunch  of work in this repository, you've been using the
00:27:46.240 hash command to actually add memory, you go to  another repo, you're working on another project   and suddenly your cloud code instance is no longer  as smart. Like it just it gets lost way more and
00:27:57.200 you're like what's going on? You realize all that  knowledge, all that intelligence, everything,   it's all in that other repo. So then you're like,  okay, let me just copy it over. Nope. Because it's
00:28:06.880 full of a bunch of stuff that only belongs to that  repo. So you're left managing these huge files and
00:28:12.720 it's nasty. So what this system does is build this  nested tree structure that instead of doing it all
00:28:21.840 in one file inside of the repo, you put it all in  the nested structure so that when Kai spins up,
00:28:30.960 when your PI spins up, it goes and hydrates with  the right amount of context at the right time.
00:28:40.560 So th this is just so critical. This is just like  this is the magic. And I'm telling you right now,
00:28:47.520 this thing is like the effectiveness that I have  now over the last few months of using this is like
00:28:55.600 night and day different. Completely different than  cloud code by default. Oh, another shout out to
00:29:02.480 um to the Manis team. They had a really  cool post about doing this for sub agents.
00:29:09.840 um and or Jason was talking about doing this  on for sub agents. So this is AI Jason Zho and
00:29:16.160 uh he makes great videos. You got to go check his  stuff out. But he was talking about doing this for   sub agents recently. So same sort of concept.  Um okay except for just the scope is different,
00:29:27.200 right? So system in action. All right. So this  is example of this working. Um, this one is
00:29:34.080 actually just showing that we actually called the  right agent which was developer. So I asked uh,
00:29:39.840 hey go fix the live view page of site analytics  dashboard and uh, if the link is internal, I
00:29:45.840 wanted it to show after the URL on the same page.  Spammers. Okay. And the agent went and executed
00:29:53.120 this perfectly. So Kai spun up the developer  agent and went and executed this perfectly and
00:30:00.080 actually produced this um which just switch over  here live. See what it looks like. See if there's
00:30:06.960 any incoming internal. Yeah, look at this internal  projects pointing to projects. So that was what
00:30:14.000 Kai went implemented for that. Pretty cool. So the  other piece which is just like standing on top of
00:30:23.600 this is this whole blog post I actually edited or  I dictated with whisper flow using two fingers and
00:30:34.880 I just basically did the entire flow describing  the entire system. That's how this whole blog   started. And since then I've been collaboratively  editing the site saying no move that above. Oh,
00:30:47.200 go get a code snippet from here. Whatever. I'm  just talking to Kai. This image right here,
00:30:53.440 I said I took the screenshot. Um, Kai actually  could have taken the screenshot with uh Playright,
00:31:01.760 but anyway, I took the screenshot. I said,  "Hey, go put this in in the appropriate section   or whatever." Boom. And plus the caption. So  ridiculous. So, not only is Kai finding the right
00:31:14.480 agent to use, using the right knowledge to make  it happen, actually fixes it, upgrades the site,
00:31:21.760 implements the feature, and then to talk about  it, puts it in the blog post where we're actually
00:31:27.680 talking about Kai himself. And this is all using  this infrastructure um minimalclaw.mmd that points
00:31:36.960 to the nested trees of context underneath context.  So um this is what the website claw.md actually
00:31:46.480 looks like. And um again Kai went and got this  for me. This is the actual code and I'll keep
00:31:51.600 this updated as well so you can keep uh seeing  or you could just respond in the comments and
00:31:57.200 I don't know maybe I'll put that in like a a  gist or something for um on GitHub. So this is
00:32:02.320 the concept right the actual expertise lives in  the nested sections. It lives nested underneath
00:32:08.960 the sub areas so that you're not just loading all  this crap in there that you don't actually need.
00:32:15.600 Give the agents only what they need, right? So  some examples, additional examples here of what
00:32:23.440 you could do with that. Okay, next piece here.  Absolutely, absolutely super important. Setting
00:32:27.000 No text
00:32:30.480 up tool usage within this context system. So this  is one of the most important things because this
00:32:36.480 is how a lot of AIs get lost, right? They don't  understand what they're supposed to use to answer
00:32:42.240 the particular requests that you're asking.  So within this type of system, it is so much
00:32:48.400 cleaner. Okay. So instead of cramming everything  in to the single files, it's under context/tools
00:32:56.720 and then the cloud MD file. And there I have all  the different tools that I have, all my commands,
00:33:03.280 all my PI commands which are like custom things.  I'll talk about those later. Those are called   FOBs. Talk about that in another video as  well. Um so those are there. MCPS as well
00:33:13.680 are also described there. But watch this. This  doesn't matter if the context doesn't get loaded
00:33:20.640 correctly. So this piece is clutch. It's critical.  Absolute must have this piece. So how do you get
00:33:29.040 your AI to actually read the context that it needs  at that particular moment? Right? So watch this.
00:33:38.240 even with instructions in the cloud MD it could  it could say it read it and it didn't read it or
00:33:44.480 it could read it and it just gets overwhelmed  because haystack problem um or maybe it's just   too much content like what whatever there's so  many reasons this can go wrong so what I've done
00:33:53.920 is I've built a four layer enforcement system um  to there's like different on-ramps to make sure
00:34:00.160 we actually get to the place we're trying to go to  make sure the context actually does get loaded and   it's actually what Kai is So the first one is we  load this file. This file describes the overall
00:34:14.159 context management system uh which uh I'm calling  UFC uh unified or universal doesn't matter. File
00:34:21.760 system based context file system based that's  the F. So this describes that whole system. It
00:34:29.840 describes the nesting. It describes that you're  not supposed to put too much and you're supposed   to refer to the lower levels. So this is the first  thing that gets loaded describing the overall UFC
00:34:41.040 system. Second one is a user prompt submit hook.  This one actually when you load a request. So the
00:34:49.760 hook system is really cool. You should go read  about it. Um I'll put a link down there. I think
00:34:55.920 when you send a prompt into cloud code, you have a  hook opportunity. So this hook opportunity, I tell
00:35:03.120 it to make sure you've read the context, right?  So it reloads it and um it it's just unbelievable.
00:35:11.280 So here's the actual code for that. This is what I  actually have sent in the hook. So it's read these
00:35:16.800 these three right here. very similar to what I put  in the prompt as well and in the cloud.md. So the
00:35:25.040 power of this is like if you combine all four of  these, actually we're not even done with all four,   but it's system level enforcement, right? To to  not rely on cloud code to actually remember this,
00:35:37.360 but to just like kind of force the issue to  to ensure and repeat and uh yeah, just add
00:35:45.280 structure to it. So he's actually doing what he's  supposed to do. So layer three, aggressive claw.md
00:35:52.960 instructions. I mean, you can't really get around  this. So yeah, I got sirens, I got spinny things,
00:35:59.200 I got like I'm making it clear. I also put it at  the top. So once again, I'm telling this these are
00:36:05.280 the context files that are important. And then I  get this cool little uh result at the end saying
00:36:11.920 yes, I have in fact loaded them. So re really  really cool. Um, and that is in the claude MD
00:36:18.160 files themselves. And finally, this one. I'm not  actually sure if this is like super important or
00:36:23.760 how much it works or how much it doesn't work, but  what I do is I just sim link claw.md inside of the
00:36:30.320 clawed directory inside of every repo to actually  point out to the parent directory one directory up
00:36:38.640 claw.mmd file just in case they get lost in their  own clawed directory. So all of these combined
00:36:47.280 and like I said I am telling you way beyond cloud  code in terms of staying on the rails. It is just
00:36:54.000 night and day difference. I'm at like way over 90%  95% like compliance with like staying on task, not
00:37:03.280 forgetting tools, stuff like that. Okay, so demo  of this thing actually loading context. So I fire
00:37:09.440 up uh Kai and Kai loads up and what do we got? We  got him reading the files and outputting that he's
00:37:15.000 No text
00:37:18.800 good to go. Look, I'm aware of active projects.  I know my commands and capabilities. Super sick.
00:37:25.280 And then fires up the correct agent, which is  developer. So yeah, just just awesome. So all
00:37:31.840 this is basically what he's doing on every single  load, which keeps him going down the correct path.
00:37:41.520 Yeah. And all the language about you got to  be careful blah blah blah. This is just as you   know if you're watching this is just standard  uh fair for AI. You basically have to do this
00:37:52.640 uh sort of language and put it at the top and  all that. Um but ultimately what we're getting
00:37:58.960 is actual context hydration as a result of this  whole thing. So this piece is super critical.
00:38:04.720 It's not just a sub aent system. It's not just a  tool system. It's not just a project system where
00:38:10.640 you're hydrating with context inside that folder.  It's the entire underlying platform itself. This
00:38:17.280 is an upgrade to claude code itself. Right? Using  this type of file system for context and here's a
00:38:20.000 No text
00:38:25.600 demo of this that is just super ridiculous.  Um I've got tons of friends who are also
00:38:31.760 uh you know devs in the space actually building  stuff apps and companies. when I show them this,
00:38:37.680 they [ __ ] themselves. Like without question,  they [ __ ] themselves. Uh so so here's the
00:38:42.960 question. Here's the thing I give to uh  to Kai. Uh give me the takeaway from the
00:38:48.400 meeting today that mentioned Alex Hormosi. And  this is from a real meeting I actually had. So
00:38:54.880 um completely fresh session with Kai. No context,  no instructions, just the regular hydration that
00:39:00.400 normally happens when a system when Kai boots up.  And uh this is what it has to do for this to work,
00:39:07.200 right? And so here's what Kai did. Look at this.  What was my specific takeaway from last meeting
00:39:13.280 related to Alex? So that was the actual  question I asked. Look at this. Loads the   context. Let me search for information. Boom.  Finds it. My tool is called get lifelog. Okay.
00:39:25.360 So how is it actually getting this? How did  it actually record this? Because it wasn't   like Zoom. It wasn't like Gong or anything  like that. No, it was actually this thing.
00:39:37.200 Limitless. What was it? Limitless.ai. This  is like the only like live recording thing
00:39:43.600 that I use. I tried the Plaude one. That  didn't work for me. Um, and by the way, no,
00:39:49.280 I'm not about to switch into a sponsor spot. Um,  not sponsored by these guys. It's just sick. It's
00:39:55.840 just sick. And they have an API. Most importantly,  they have an API, which is why I bought it.   And I was pulling that from that API with curl  before because I'm a command line nerd and I'm
00:40:05.840 happy on the command line. This is where I say  usually. And that was great. But then going back
00:40:10.960 to the creativity thing, why not just ask Kai? So  I ask Kai, look what he says. I found it based on
00:40:20.640 your limitless pendant recordings. Here's what  you discussed. Boom. And gives me the answer.
00:40:29.280 He actually did it. Actually gave me the  answer. And he does it every time. Every
00:40:35.680 time. Like he doesn't miss. So um actually let's  um let's try and actually do a demo of this. So
00:40:46.400 I'm going to hyper J over here. Okay. So we  are over here. We're going to do this. We're
00:40:53.200 going to launch Kai. Kai here. Ready to go. and  having some issues with Anthropic right now,
00:40:59.440 but we're going to see if we can launch  this thing. I'm going to say, "Hey, I had
00:41:04.800 a meeting earlier and I was talking uh about some  advising with the the company I was talking to,
00:41:10.560 the person I was talking to. I just want to see  like what was the overall topic of that advising
00:41:16.320 conversation." And don't put anything sensitive  because I'm actually recording right now.
00:41:23.920 By the way, I did uh command J for that  because I'm on my Vim hotkeys to be able
00:41:30.640 to talk directly to Whisperflow and dictate  right into Kai. Okay, let's read some context
00:41:38.080 files. Let's not go super slow. Cool. We got  the tools. I think there's one more to read.
00:41:50.640 Okay. recent meetings or recordings and  it found the right tool. Get lifelog. So,
00:41:57.920 let's see if we could pull the transcript from  the API automatically and pull out what I said
00:42:06.640 and hopefully it won't be sensitive about the  person or the company. Hydration complete.
00:42:15.920 All right, we got our API call post interview reflections. Yep, it was  after the interview. We were still recording,
00:42:25.440 but today's recording. Yeah, I was looking at more  recent content. So, an agent completed advising
00:42:32.880 conversation topic retrieval successfully. And  there we go. This is exactly what I talked about
00:42:39.360 with the person. Yeah, I'm actually super excited  about that conversation, actually. Yeah. So, it
00:42:45.920 pulled everything out exactly as I would expect.  Okay, perfect. So, I'm going to switch back. Yeah.
00:42:51.200 And once again, he actually did. It happens every  single time. Ask a simple question, starts looking
00:42:57.200 at context files, realizes he needs to look in  a particular place, figures out it's life log
00:43:04.080 command, and goes and extracts the exact thing  we're looking for. Uh, in this example in the
00:43:09.120 blog, it was the Hormosi thing. In my example, it  was the advising thing. So yeah, reading all this
00:43:16.400 context and doing all the things all based on that  actual nested context, right? So going back to the
00:43:25.000 No text
00:43:27.760 DA piece, this is the critical part of a DA is you  could just throw things over the wall. I didn't
00:43:34.560 say limitless AI. I didn't say live recording from  a device, right? That stuff is supposed to come
00:43:41.600 from your nested context. Otherwise, you know,  we're not really gaining anything here because you
00:43:47.920 have to explain yourself constantly. So, another  example, hey, go do a basic security look at a
00:43:54.640 website, right? So, I've got a MCP for Naboo. I've  got a MCP for HTTPX. So, I can go get sight stack.
00:44:02.320 I can go get port scans. I could do whatever.  Part of a legal bounty, by the way. And um yeah,
00:44:09.680 you don't have to junk up your context. So  critical point here that's absolutely essential.
00:44:16.080 Just because you have more context, like if all  the context sizes double in a couple of months,
00:44:21.600 like that doesn't really matter that much, right?  Because that means there's just going to be more   junk in there. You still have a haststack problem.  Even if it gets better and better at haystack,
00:44:30.800 it is much better to have clean context than  a giant context that can fit a lot of garbage.
00:44:35.000 No text
00:44:38.000 Um, okay. Next one here. This is just for fun.  You've probably already seen it. I assume you saw
00:44:43.040 it in the other uh demo and also in the live part  we just did. It's just fun stuff, right? So, uh,
00:44:51.360 Kai is currently running on Opus 41 in the website  directory. He has access to 26 FOBs. Like I said,
00:44:58.240 we're going to talk about those later u probably  in another video. 23 commands, seven MCP servers,
00:45:05.040 231 fabric patterns. Oh, real quick tip. I update  Claude every single time I load it. I know Claude
00:45:13.520 also does auto updates, but I don't believe it.  I actually do a fresh install each time and just
00:45:19.120 uh that's the command I use bun because I don't  like npm. Okay, fobs and commands modular set
00:45:20.000 No text
00:45:27.760 of tools that could do one or one thing well and  could be called by various agents. And that leads
00:45:33.040 right into the next section which is super super  important. I only want to make things once. I'm a
00:45:41.280 Unix nerd all the way back. All the way back Unix  nerd. Okay. So I only want to solve a problem once
00:45:48.160 and turn that into a command. Turn that into a  module. Turn that into a tool and then integrate
00:45:54.320 it into the overall system. And it is so so fun  to do this because you're just like you're just
00:46:00.400 making this this robot this giant robot more and  more powerful and smarter and more effective and
00:46:08.400 more capable. Right? So good example of this is  my create custom image command. Um which has been
00:46:15.920 making wi-i which did make all those images that  I showed you that Kai made. Kai used the create
00:46:21.600 image command. But guess what? I had Kai write a  blog based on the narration that I gave, based on
00:46:31.040 the dictation that I gave. He wrote this, right?  Or a lot of it uh because it's been modified since
00:46:37.360 then. But he wrote the structure in my exact  format which is also part of write blog which
00:46:43.600 reads from guess what context projects website  content that is what that's the actual structure
00:46:53.280 for kai where write blog is talked about and  inside of write blog is create custom image and by
00:47:01.520 the way both of them are also in the tools context  so it just understands how to do things. But the
00:47:09.200 important part is it's nesting singular commands.  So just like with Unix in a shell script, you
00:47:16.320 could have, you know, nine actual commands stacked  together, piped together to get an effect, but
00:47:24.880 that thing itself is called another thing, right?  So this Unix philosophy is like deeply embedded
00:47:31.600 in like this whole entire UFC thing. Another thing  to mention about that is like you can do this with
00:47:37.520 a slash command, right? But a slash command makes  no sense to me because I want a digital assistant.
00:47:43.680 Again, I'm building for the future. I'm building  Kai to be my digital assistant, which means I just
00:47:48.880 want to say get that information about advising in  the meeting that I was just in. That's literally
00:47:57.440 what I said. That's all I want to say. I don't  want to go to the command line and forward   slashtype get lifelog and then type out, you know,  the thing I'm looking for like no no voice voice
00:48:14.560 um throw it over the wall. The the pure concept  of a digital assistant is what I'm looking for.
00:48:20.400 Yeah. So, what I'm talking about is the chaining  of this stuff is where all the power is. Okay. Uh,
00:48:27.200 next piece here, agents. Pretty straightforward.  One thing that I do different with agents that   I think is uh, important. So, agents actually  have a system command at the top and then a user
00:48:28.000 No text
00:48:38.960 um, prompt at the bottom. So, what I've done is  I've actually taken that same context that I put
00:48:45.440 at the top of CloudMD files and that's actually  loaded in the context as well and also in the
00:48:51.840 um, user agent hook. And what I've done is I've  taken that and put it in the system prompt for the
00:48:58.320 agents. So they actually get hydrated immediately  with the right context before they even start. So
00:49:00.000 No text
00:49:05.920 uh a little bit of a super tip there. Yeah. Next  piece to mention here just real quick is that
00:49:12.000 fabric patterns are markdown. Commands in cloud  code are markdown. Um fobs I think I mentioned
00:49:21.200 this before. FOBs are basically markdown files  that when you create them or load them within
00:49:29.920 about 5 seconds after I commit they become  actual MCP tools but fundamentally they're
00:49:36.800 still constructed out of markdown. So extremely  powerful and commands which uh I think that's
00:49:45.680 the one everyone is most familiar with and you'll  see some of the uh the most common ones here that
00:49:51.600 we've kind of already talked about and seen. And  finally MCP servers and by the way this is nested
00:49:57.200 underneath the tools directory. There's also an  MCP one. There's also a PI one, PI, personal AI
00:50:03.200 infrastructure. That's where I have my FOBs. And  there's also a commands one and an MCP one. Um,
00:50:08.880 so all of those are there. Oh, and by the way, the  MCPS that I run, I've got a whole bunch. Actually,
00:50:09.000 No text
00:50:14.480 I'm going to show you my exact uh file here in a  second, but I've got a whole bunch of these. And
00:50:20.480 um, a lot of them are my own that I've actually  made. Um, Kai wrote the JavaScript, by the way.
00:50:29.040 Uh, so Kai actually built these. He built a tool  for building these. Okay, so this blog post,
00:50:35.040 actually this is my blog post, but it references  a blog post by Cloudflare that said, "Hey,   why don't you build MCPs on Cloudflare?" I'm  like, "Yes, please." Because I actually don't
00:50:43.680 want to run the infrastructure for these MCPs.  I really don't. Um, I don't like having that   running local and it has to be up if it works.  No, I want it all remote and always running. So,
00:50:53.440 when this blog post came out, guess what? I gave  it to Kai and I said, "Hey, turn make it me a
00:50:58.720 command that allows us to build MCP servers." So,  I now have a content MCP for all my content going
00:51:06.000 back to 1999 that includes a vector database  with 1024bit um embeddings. The thing works
00:51:16.000 amazing. Uh it's also got a KV store in there  as well. It's like it's the sickest thing. And
00:51:21.200 that took about seven minutes to make just using  this blog, just using Kai. Like seriously. And now
00:51:27.760 it's a command which I could use to make other MCP  servers. It's absolutely ridiculous. So, I've got
00:51:33.600 a bunch of internal NCP servers. Well, let's just  scroll down. I've got the actual thing here. So,
00:51:38.720 um yeah, this one is I can get sight stack  information, so I know all the different
00:51:43.760 tech on the site. This one is the content. Yeah.  Uh content, opinions, posts, everything. Damon,
00:51:49.000 No text
00:51:53.680 don't even get me started. Don't even get me  started. Okay, Damon, I can't believe I haven't
00:51:58.880 talked about this. All right, it's too big.  It's about another video. Damon is my own Damon,
00:52:05.920 my own broadcast of myself in my current  state. It's live. Damon.danielmester.com.
00:52:11.360 You go there. It's a website. When the website  loads, it loads MCP.damon.danielmester.com.
00:52:21.520 How is that working? by an MCP which Kai  built which used that Cloudflare MCP blog
00:52:29.680 post. Ridiculous. This is an MCP that has all my  FOBs underneath it. And if I go right now, which
00:52:38.400 I'm not going to because this video is already  long. If I go right now into this directory and
00:52:46.240 I make a new markdown file that says talk like  a cat, I can now call that via HTTP or as an MCP
00:52:55.520 tool and it will talk like a cat on anything I  send in. Dynamically generated MCP tools using
00:53:04.000 markdown files. The these are the FOBs. Completely  ridiculous. Uh this is the port scanner I have
00:53:11.200 running. I could just call from. And this is how I  crawl stuff. Like if I can't get in any other way,   I use bright data. It's like my go-to for getting  stuff. And I got descriptions in here for each one
00:53:22.240 of them. Uh just in case you are not watching the  video and you're just reading the blog. So putting
00:53:26.000 No text
00:53:28.560 it all together, we now have this unified system  modular. do one thing well, do it once, be able to
00:53:36.800 chain them together, all unified in this central  context substrate, the UFC thing. And yeah, you
00:53:44.640 just got a million examples of stuff you could do.  I I literally talk to Kai all day exactly like a
00:53:50.880 DA and say, "Hey, go get me this. Hey, go research  that. Hey, let's make a blog post about this data   set and blah blah blah." And uh people are losing  their jobs and blah blah blah in tech. Go find
00:54:01.040 the best data sets. visualize it with D3. Like I  just say anything and Kai just goes and does it.
00:54:10.000 No text
00:54:11.680 So speaking of that, what have I  actually built with this stuff? Okay,   so first of all, newsletter automation. Got a  newsletter. It's called Unsupervised Learning,
00:54:19.600 just like everything else. Go check out their  newsletter. It's pretty cool. Comes out weekly.
00:54:25.600 But my automation that I do, if I go right here  to Feedley and I click on uh essential adventures
00:54:33.760 in state space, I don't know what that is. Sounds  cool. I click right here. That just kicked off a   giant workflow going through Zapier. going through  a whole bunch of stuff, giving me a summary of
00:54:43.520 like who who the authors are, who wrote this  thing, what's it about, what are the categories,
00:54:49.040 how high is it rated in terms of quality, and  basically gives all that in a workflow that I
00:54:55.120 can go and use to start writing about it um after  I go read the article for the newsletter. So,
00:55:03.760 uh super super cool workflow that's actually very  tangible and I've been using for years already.
00:55:06.000 No text
00:55:09.600 threshold. This one is solving a problem that  I specifically have of like I just follow too   many people. Um I've been using RSS since I don't  know whenever it came out. That's when I how long
00:55:20.880 I've been using it. And so I have thousands  of sources. So what I've done is I've brought
00:55:26.800 them all together and I've got a filter for all  my YouTube which get turned into transcripts,
00:55:33.520 all my blogs, all my RSS and it goes through a  filter and it rates them in terms of quality and
00:55:38.880 also tags. Actually, let's just pull it  up. Yeah. Threshold. Am I logged in? No.
00:55:47.760 Hacked. Names divulged.
00:55:53.360 Boom. So, this is filtering all of my sources over  3,000 sources to pull in. And it's finding things,
00:56:02.960 and it only shows me stuff that is rated higher  than this. Watch this. I'm going to go from 60
00:56:08.480 to 95. I'm going to hit save, and this list will  change. [ __ ] So, anything that's listed here, it
00:56:17.360 doesn't matter what the title is, I am guaranteed  to love it. That's the tool. That's the reason I
00:56:22.800 built this. It's also a product. You actually buy  it and use it and everything. So, it's actually   live and it's like a real thing. But a big sort  of like premise that I do for building everything
00:56:35.120 is like is it useful for me? So, the newsletter  thing obviously threshold for me obviously because
00:56:41.120 I care about being up to date and stuff like  that and not wasting a bunch of time on content   that I shouldn't be looking at. And obviously the  services that I build because of this very thing,
00:56:46.000 No text
00:56:51.680 they're going to be different than the ones that  you build, right? Um, oh, and this one is super
00:56:57.920 super important. I keep saying that. I've said  that like nine times. Threshold is made from the
00:57:05.040 components of Kai. Okay, it's made from the  same components. Again, I only build a thing
00:57:14.880 once. Okay. So what what is threshold? Collection  filtering, labeling, rating, the quality of and
00:57:26.080 showing an interface and and a stripe page. That's  it. That's it. Right? So these are these are small
00:57:34.960 little system components. So I could literally say  to Kai, "Hey, so you have all these capabilities.
00:57:40.320 Go build me a website that does XYZ." Oh, and  actually let's go further down. Let's go further
00:57:47.200 down. Um, yeah, here we go. Yeah, this is the  point I was making before. Solve the problem once,
00:57:56.080 it becomes part of the rest of the system. This  is the Unix point. This is the uh, you know,   services point that you can make products with.  It's all the same [ __ ] Intelligence gathering
00:58:03.000 No text
00:58:05.760 system. This is one I'm currently working on.  Guess what? I'm going to tell Kai, hey, we're   building a system. You know, all those super smart  OSEN people, all those super smart recon people
00:58:16.560 who could like tell what's in the back of a truck  in Iran based on the tire tread, they're like,
00:58:21.600 "Oh, that's a P2839 space missile obviously based  on his tire tread." And I'm like, "Damn, you're
00:58:30.080 smart." Okay, so I get his opinion. I get someone  else's opinion. I collect these opinions all into
00:58:36.640 one place to try to figure out if they're talking  about the same thing without even knowing about
00:58:41.680 it. Why? So I can make myself a daily presidential  intel report for cyber, for national security,
00:58:49.680 for all this stuff. Once again, am I going to make  this a product? 100%. I'm going to put a Stripe
00:58:54.720 page on it. But the reason I made it is because  I need it, cuz I want it. And guess what? That's
00:59:00.320 going to be an API that Kai can call. So, I could  literally be at dinner and just be like, "Hey,   Kai, what happened today? Like, anything crazy  going on?" And Kai's like, "Yeah, I actually think
00:59:10.560 uh so and so might actually move into soand so and  uh it might be a good time to buy so- and so stock
00:59:17.840 because if that happens, this is going to happen."  And I'm like, "Oh, really? Why do you think that?"   It's like, "Well, these 39 people kind of pointed  at it and they don't really know about each other
00:59:28.400 and it just like pieces all this stuff together."  And once again, I'm not having to go to the   interface. I'm just asking Kai, right? So all this  [ __ ] working together just it's just the best.
00:59:43.120 Okay, custom analytics. Okay, last example of  doing this. So I was working on my newsletter like
00:59:49.000 No text
00:59:50.640 two weeks ago or something and I was like, man, I  really wish I had Chartbeat. It's like this Google
00:59:57.600 Analytics replacement, way better than Google  Analytics and it was just so good and they started
01:00:04.560 charging like hundreds of dollars a month which  I'm not going to pay. And um so I'm like okay
01:00:09.760 well I turned that off and then Google Analytics  went to [ __ ] uh when it converted to version 4.
01:00:17.440 So I'm not using that anymore. I started using  Fathom which was okay. It looked pretty good.
01:00:22.480 It was functional. I liked it. Okay. But it didn't  have any of the stuff that I actually wanted. So I
01:00:30.080 suddenly had a flash. I I might have actually  been writing the post about creativity and
01:00:35.520 how we're limited in creativity. And I happen to  have this thought at the same time of like, well,
01:00:41.200 there's no way I could build Chartbeat. Obviously,  there's no way I could build Chartbeat. Chartbeat   has had a team working on this for over 10  years. It's obviously extremely difficult.
01:00:52.000 I asked Kai to build me chartbeat. I narrated with  my two fingers. Whisper flow talked for like four
01:01:00.480 or five minutes. Basically said, "Yeah, and it  should have this and it shouldn't have that."   And the analytics.js uh thing should have this.  I want to know if people are reading the site,
01:01:10.160 not just if they hit the site. I want to know  who's actively reading, you know, don't log IPs,
01:01:15.920 like a whole whole bunch of different stuff. I  I said as a spec 18 minutes later I no [ __ ] no
01:01:23.760 [ __ ] I have incoming hits of who's reading  what page. And and this is this is literally
01:01:30.560 the thing. This is literally um this is a  better version. It's nicer looking. Actually,
01:01:39.440 it was just as nice looking. It just didn't have  as much detail. Okay, so this is like a further
01:01:45.120 form of it, but Kai built me this in like 18  minutes. No [ __ ] No [ __ ] I had incoming
01:01:53.680 hits already happening and I'm like, "Holy crap.  I'm over here talking about creativity and how
01:02:00.000 No text
01:02:01.840 we should think bigger and I'm literally facing  this problem every day, not realizing like what
01:02:08.080 we're capable of when you have a system like  Kai." And yeah, perfect example of this thing
01:02:14.000 right here. Third limitation to creativity is not  realizing that our previous constraints no longer
01:02:19.600 apply. You have to retrain ourselves to think much  bigger. So going back to the human piece here,
01:02:28.000 No text
01:02:30.000 augmented capabilities. I want to help people  have this. I want everyone to have this,
01:02:37.040 right? Not just nerds like us. If you're watching  this video, you're a technical person, right? It's
01:02:46.000 not just for us. AI is not just for us. Artists,  writers, creative people, anybody doing anything,
01:02:52.880 I could have a five-minute conversation with them  and light up their brain with like, what could you   do with a thousand employees? They're like, "Oh,  well, I would start this business and I would like
01:03:02.000 I'd be doing a plant nursery and I would be doing  all this other stuff and I would have my own art,
01:03:07.280 you know, place and I'd open up a place and I'd  have an arcade and like, you know, kids would come
01:03:12.400 in and I would teach them about literature and  like they just start lighting up with all these   other ideas of like what they could do. This is  what I want to give them. This this is what this
01:03:21.840 type of system is designed to give people in  general." Thanks again to Kai for the image.
01:03:28.880 So basically, okay, let's say it's an artist.  Okay, I want to help people transition out of this
01:03:35.280 world where they can't do what they want to do.  They they're they dread Mondays. The their real
01:03:41.600 life is like stuck away in their brain and their  9 to5 is like spreadsheets and like I just wish
01:03:46.640 I didn't have to do this. Well, guess what? That  eats up their whole day, not counting commute if   they have to go in. It's it's nasty. This is the  whole thing with the end of work at the top of the
01:03:57.040 post, right? Well, if it's an artist, I don't want  them to be surprised. I don't want an artist to
01:04:03.280 ever say, "Oh, really? That my favorite artist, he  came to town and like I didn't even know." Like, I
01:04:11.280 didn't even know they were in town. I didn't know.  I I wanted to take one of my pieces to show them,
01:04:16.560 you know? It's like I don't want that to happen.  I I want them to be able to go and collect the
01:04:22.720 artists that are around them. I want them to  like find their email addresses if they have   it published like live and public and just be  like, "Hey, let's reach out. Hey, Kai, can you
01:04:25.000 No text
01:04:31.840 reach out to this artist and say, "Hey, you know,  I'd really love to uh connect with you. Let's get   a coffee. Love to show you this piece and see what  you think." Right? I want to empower everyone with
01:04:43.680 this same capability. So, that's what this is  really about. Okay. some caveats and challenges
01:04:50.080 with the system. Uh, this one we talked about  earlier, you need great descriptions for all your   different tools inside of the system. Um, you want  to keep your context documentation updated. So,
01:05:01.200 the whole UFC thing, you want to keep those nested  structures, keep them updated. And it's actually   way easier with a nested structure because you're  kind of only updating in one place and you don't
01:05:11.200 have to like find a place inside of a larger one,  right? Because that gets nasty pretty quick. Um,
01:05:17.360 also don't forget your agent instructions. Like  I said, I just put that priming of the context
01:05:23.000 No text
01:05:23.360 uh hydration into the actual system  prompt and that solves it for me. Okay,
01:05:29.680 this one's a practical takeaway. Uh, a way of  thinking about future product releases from
01:05:35.040 all these different AI vendors. So um going  forward when you see all these new releases,
01:05:41.840 all these new models, all these new features,  even in cloud code, which is my favorite system,
01:05:48.480 think instead not about the FOMO. Don't chase the  shiny, right? Everyone's getting like the FOMO,
01:05:55.120 the shiny FOMO about the new uh feature, and  that includes me. What can I actually do with
01:06:02.800 it? That's the question I ask myself now. How does  this improve Kai? That's my number one question.
01:06:08.560 How does it specifically upgrade your system? That  is the most important question. So stop thinking
01:06:14.880 about features in isolation and think about how  they contribute to the whole and use that as your
01:06:21.120 benchmark for whether or not it's worth your  time to go mess with it. And zooming out again
01:06:26.000 No text
01:06:29.920 and looking forward. So, what I'm actually  building towards, love this picture. This
01:06:35.280 uh older version of midjourney made this for me.  So, what does an ideal pie look like? For me,
01:06:42.320 it comes down to being prepared as possible for  like whatever happens, right? I don't want to
01:06:48.560 be surprised. Ex-military, that probably helps. I  don't like being surprised by things. I don't want   to find out that the best book ever came out six  months ago and I should have read it. Okay. Victor
01:06:59.360 Frankles. um book, the the most important book  ever. I didn't read it until a couple of years
01:07:07.680 ago. That's ridiculous. That's a crime. And so,  I don't want that to happen. New things come out,
01:07:15.040 new blogs come out. My friends write a blog they  haven't written in two years. I want to know about
01:07:20.160 that. I want to reach out to them. I want to  call them on voice and be like, "Hey, you know,   I saw your writing. I think it's super cool  that you're writing. I want you to keep it up."
01:07:28.720 Like I want these things, interesting things,  important things that are happening in the actual
01:07:35.120 world of humans. I want to be aware of them. I  want to be entwined in them. Um I don't want to
01:07:41.360 be surprised security-wise. I don't want to end  up in a bad neighborhood when I shouldn't. I if
01:07:46.480 there's some sort of altercation going on at the  restaurant two doors down, maybe I need to get
01:07:52.240 away from there. Maybe I need to go help, right? I  just don't want to be surprised by things. This is
01:07:57.440 ultimately what I'm looking at. So I recommend you  check out this post. This is also whole separate
01:08:02.960 talk show, but um it's basically more about where  I see things going in the future and how all this
01:08:09.280 combines and all works together. Uh a lot of the  stuff we touched on, but in much more detail and
01:08:14.880 sick graphics, including some that you see here.  So you should go check that out separately.
01:08:20.399 Um, and the question is like, well, how is Kai  going to make all those things and those examples
01:08:25.600 actually happen? Well, I think it's using those  four things that I talked about earlier, which is
01:08:32.720 um updating an AR interface to basically provide  that data. And how is Kai going to know uh what AI
01:08:41.279 interface to use or AR interface to use inside of  my glasses? Because that will be a company itself.
01:08:47.760 The company providing the interface will be in a  list of companies competing for interfaces. All
01:08:54.080 the marketing, all the marketing for cool tech to  do inside of a tech stack, cool tech to go inside
01:09:00.560 of glasses, all that marketing is actually coming  to Kai. I'm not getting that marketing. I can't
01:09:06.080 read the API. I can't make the interface. Kai is  getting all this marketing when I'm like, "Hey,
01:09:11.279 I want a really cool security view like minority  report. When I'm going into this town in Europe or
01:09:17.279 whatever and I want to see like cool red things  and people have outlines and blah blah blah,
01:09:23.040 Kai's like, "Okay, cool. I will go look at a list,  a live list of the highest rated ones of these,
01:09:30.720 right? And those will all be provided by  the companies themselves making those. and
01:09:36.560 a different company will make the interface. A  different company will have the data for that.
01:09:41.600 Right? All these will be different things. Um  and what I talked about for this uh in the book
01:09:47.920 was basically companies as APIs. Companies become  APIs that provide our DA's context in this way.
01:09:56.800 So Kai is basically building this world for me.  constantly optimizing my experience, reading the
01:10:03.280 dammons around me, orchestrating thousands of  APIs simultaneously, and crafting the perfect
01:10:10.080 UI for every situation. And the reason he's able  to do this so well is because he knows everything
01:10:17.680 about my goals, preferences, and what I'm actually  trying to accomplish as a human in life. And that
01:10:24.080 is what I'm actually trying to do here. That is  the why and the what and the how. So the summary,
01:10:25.000 No text
01:10:30.720 think about what we're actually building  with all this stuff. My answer is a personal
01:10:36.480 AI infrastructure, system over intelligence,  text as thought primitives, file system based
01:10:45.600 orchestration, solve once, reuse forever with the  Unix philosophy, and don't chase the shiny. Think
01:10:54.160 about how the stuff incorporates into your  overall system. This is my life right now.
01:11:01.120 It honestly is. This is what I'm building. This is  what I'm so excited about. This is why I love all
01:11:06.240 this tooling. This is why like I'm having trouble  sleeping. Honestly, since I would say two months
01:11:12.320 ago or so, two, three months ago, I have trouble  sleeping because I just wake up, I fly over here,
01:11:18.720 and I sit here for six hours and accidentally  like six hours is gone because I'm building [ __ ]
01:11:26.080 adding new functionality, creating a new tool,  building a new module, tweaking the context
01:11:31.280 management system so it kai stays even more  on the rails, new sub aents, and ultimately to
01:11:37.840 improve things, to improve like what I'm trying to  accomplish as a person. So, I really do hope that
01:11:44.000 this gets you as excited as I am about building a  system like this. I really hope it makes you want
01:11:50.000 to build your own. And uh there's just never  been a better time. Like things are crazy,
01:11:56.560 absolutely chaotic. Things could go really badly  honestly with the whole AI thing. And being a
01:12:03.280 security person, like I think about this a lot,  but I choose to think of the better option, the
01:12:11.440 human 3.0 option. And even if it's a tiny chance  that we're actually going to get there, what else
01:12:17.360 am I going to do? I'm not gonna sit around and  fret and worry and like be a doomer. I'm going to
01:12:23.040 like lock onto that thing, describe it to others,  hopefully get people excited about it, and then
01:12:30.320 build the tools and the systems to hopefully help  get us there. So, if you're interested in this,
01:12:37.760 if you want to build a similar thing, if you  just want to follow me like making this happen,
01:12:44.560 uh check me out on uh YouTube. you're watching  this on a video, just hit all the YouTube buttons.
01:12:50.400 I don't know how many there are. Probably seven  or eight. I don't know. Like, subscribe, all that   stuff. Hit each of them like three or four times.  And uh newsletter and Twitter and X. Reply in
01:13:02.000 the comments. I will actually respond. And uh go  build some stuff. We'll see you in the next one.
